# Extracting Explanatory Rationales of Activity Relationships using LLMs - A Comparative Analysis

Business Process Redesign (BPR) is essential for adapting processes to technological advancements, legislative changes, and sustainability standards. Despite its significance, BPR faces challenges due to limited automated support, particularly in classifying activity relationships that govern execution order. This comparative analysis investigates the use of Large Language Models (LLMs) to automate the extraction of explanatory rationales—laws, business rules, and best practices—from textual data, addressing the traditionally manual and resource-intensive retrieval process. By comparing four LLM prompting techniques (Vanilla, Few-Shot, Chain-of-Thought, and their combination), we evaluate their effectiveness in classifying relationships based on contextual origins. Our findings show that Few-Shot and Chain-of-Thought approaches significantly enhance precision, recall, and F1 scores. Furthermore, smaller, cost-effective LLMs, such as GPT-4o mini, achieved performance comparable to larger models, making advanced classification accessible to organizations with limited resources.

In this repository you find
* **Testing Use Case:** We developed the experimental setup based on the testing use case of the airport check-in process.
  * Process Descriptions
  * Ground Truth
  * Prompts
* **Thesis Process:** This use case scenario was used for the final experiments
  * Interview Trasncripts
  * Process Descriptions
  * Ground Truth
  * Prompts
* **Results** 
* **Python Scripts**

